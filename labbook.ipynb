{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20-10-2023\n",
    "I had the idea to combine the following two concepts into an article:\n",
    "\n",
    "- Word embeddings can be visualised with T-SNE\n",
    "- Transformer are constantly manipulating these word embeddings\n",
    "\n",
    "Combined I think we can nicely show what makes transformers tick. We visualise the wordembeddings after no or little training, and then see how the visualisation changes after more and more epochs. This should illustrate that words move in the multi-dimensional embeddingspace, showing what the model does. \n",
    "\n",
    "The idea is to:\n",
    "- Start with visualising word embeddingd with T-sne\n",
    "- Than take the embeddingspace out of a transformer and visualise that\n",
    "- Then train the transformer and make multiple visualisations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
